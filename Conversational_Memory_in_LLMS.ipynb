{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dU4Ak504cXF6",
        "outputId": "6a75443d-c68f-4eb0-fe02-c1f7680b48f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -qU langchain openai tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import inspect\n",
        "from getpass import getpass\n",
        "from langchain import OpenAI\n",
        "from langchain import LLMChain , ConversationChain\n",
        "from langchain.chains.conversation.memory import (ConversationBufferMemory,\n",
        "                                                  ConversationSummaryMemory,\n",
        "                                                  ConversationBufferWindowMemory,\n",
        "                                                  ConversationKGMemory)\n",
        "from langchain.callbacks import gellt_openai_callback\n",
        "import tiktoken"
      ],
      "metadata": {
        "id": "MdWNM23ic7RI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OPENAI_API_KEY = getpass()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnCyZLR8eXxo",
        "outputId": "97e660c9-6868-4918-f5b4-71a19ad54aa2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm=OpenAI(temperature=0 , model_name=\"text-davinci-003\", openai_api_key=OPENAI_API_KEY)\n"
      ],
      "metadata": {
        "id": "bvfLtJp0ei9v"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_tokens(chain , query):\n",
        "  with get_openai_callback() as cb:\n",
        "    result=chain.run(query)\n",
        "    print(f'Spent a total of {cb.total_tokens} tokens')\n",
        "\n",
        "  return result\n"
      ],
      "metadata": {
        "id": "zSwKIrHifDPC"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ConversationBufferMemory** :\n",
        "The ConversationBufferMemory does just what its name suggests: it keeps a buffer of the previous conversation excerpts as part of the context in the prompt."
      ],
      "metadata": {
        "id": "k0Mp2c5uf-A1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_buf=ConversationChain(llm=llm,memory=ConversationBufferMemory())"
      ],
      "metadata": {
        "id": "P1BFCuMDf5Jk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_buf(\"Good morning AI!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzDRwuNugNJL",
        "outputId": "4665d506-fab7-4078-e65b-fe00d8b57c01"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'Good morning AI!',\n",
              " 'history': '',\n",
              " 'response': \" Good morning! It's a beautiful day today, isn't it? How can I help you?\"}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count_tokens(\n",
        "    conversation_buf,\n",
        "    \"I want to know about integrating Artificial Intelligence in daily lives\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "eztevbbbgTIS",
        "outputId": "9fdd098a-7f48-46e3-f4e8-7b47cb668143"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spent a total of 206 tokens\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" Sure! AI is becoming increasingly popular in our daily lives. It's being used in a variety of ways, from helping us with our daily tasks to providing us with personalized recommendations. For example, AI can be used to automate mundane tasks, such as scheduling appointments or managing emails. AI can also be used to provide personalized recommendations, such as suggesting movies or restaurants based on your preferences. AI can even be used to help us make better decisions, such as providing us with financial advice or helping us make better health choices.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  count_tokens(\n",
        "    conversation_buf,\n",
        "    \"Which data sources can give more context for AI to train on\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "mF8SSLkqilrD",
        "outputId": "1f403c3d-2306-4695-cccf-2e66509ebacd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spent a total of 322 tokens\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' AI typically uses data from a variety of sources to train its algorithms. This data can come from a variety of sources, such as public databases, private databases, or even user-generated data. For example, AI can use data from social media platforms to learn about user preferences and behaviors. AI can also use data from sensors, such as cameras or microphones, to learn about the environment. AI can also use data from medical records or financial records to learn about health or financial trends.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count_tokens(\n",
        "    conversation_buf,\n",
        "    \"What is my aim again?\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "LWDbl1Eci1Pz",
        "outputId": "924f9dc4-3010-492f-c7fc-494f41a16b9f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spent a total of 348 tokens\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Your aim is to learn about integrating Artificial Intelligence into daily lives.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(conversation_buf.memory.buffer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kS3wupAqi4iW",
        "outputId": "3dd453e5-f6a6-47eb-ea01-ceba06052818"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: Good morning AI!\n",
            "AI:  Good morning! It's a beautiful day today, isn't it? How can I help you?\n",
            "Human: I want to know about integrating Artificial Intelligence in daily lives\n",
            "AI:  Sure! AI is becoming increasingly popular in our daily lives. It's being used in a variety of ways, from helping us with our daily tasks to providing us with personalized recommendations. For example, AI can be used to automate mundane tasks, such as scheduling appointments or managing emails. AI can also be used to provide personalized recommendations, such as suggesting movies or restaurants based on your preferences. AI can even be used to help us make better decisions, such as providing us with financial advice or helping us make better health choices.\n",
            "Human: Which data sources can give more context for AI to train on\n",
            "AI:  AI typically uses data from a variety of sources to train its algorithms. This data can come from a variety of sources, such as public databases, private databases, or even user-generated data. For example, AI can use data from social media platforms to learn about user preferences and behaviors. AI can also use data from sensors, such as cameras or microphones, to learn about the environment. AI can also use data from medical records or financial records to learn about health or financial trends.\n",
            "Human: What is my aim again?\n",
            "AI:  Your aim is to learn about integrating Artificial Intelligence into daily lives.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ConversationSummaryMemory**  - the conversation summary memory keeps the previous pieces of conversation in a summarized form, where the summarization is performed by an LLM."
      ],
      "metadata": {
        "id": "5JKqp2GDjHHl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_sum = ConversationChain(\n",
        "    llm=llm,\n",
        "    memory=ConversationSummaryMemory(llm=llm)\n",
        ")"
      ],
      "metadata": {
        "id": "7ohZA3ihi_WY"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_tokens(\n",
        "    conversation_sum,\n",
        "    \"Good morning AI!\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "qeXJF8P5mc8p",
        "outputId": "28fa5c86-714d-4c5a-bf6e-ecaa442ec2fe"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spent a total of 290 tokens\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" Good morning! It's a beautiful day today, isn't it? How can I help you?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count_tokens(\n",
        "    conversation_sum,\n",
        "    \"I want to know about integrating Artificial Intelligence in daily lives\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "Kr9a8iS9me05",
        "outputId": "44854c28-dd7d-489a-9fab-c99e9ceec4cb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spent a total of 554 tokens\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" Sure, I'd be happy to help. Artificial Intelligence is becoming increasingly popular in our daily lives. It is being used in many different ways, such as in healthcare, transportation, and even in our homes. AI can be used to automate mundane tasks, provide personalized recommendations, and even help us make decisions. AI can also be used to improve customer service, increase efficiency, and reduce costs.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  count_tokens(\n",
        "    conversation_sum,\n",
        "    \"Which data sources can give more context for AI to train on\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "s-X1rP3HmlY0",
        "outputId": "c1ea7477-1d25-44da-c2d2-e64a63a9fac5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spent a total of 821 tokens\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' AI can be trained on a variety of data sources, including structured data from databases, unstructured data from text documents, audio, and video, as well as real-time data from sensors and other sources. AI can also be trained on historical data, such as customer records, financial data, and other data sets. Additionally, AI can be trained on data from external sources, such as social media, news articles, and other public sources.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count_tokens(\n",
        "    conversation_sum,\n",
        "    \"What is my aim again?\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "HiBU1A9Dmp6b",
        "outputId": "e6463180-f204-43f6-a4b4-0f1335ece6a6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spent a total of 868 tokens\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' It looks like you were asking about integrating Artificial Intelligence into daily life. Is that correct?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In **ConversationBufferWindowMemory**  we will be keeping a few of the last interactions in our memory but we will intentionally drop the oldest ones - short-term memory if you'd like. Here the aggregate token count and the per-call token count will drop noticeably. We will control this window with the k parameter."
      ],
      "metadata": {
        "id": "dUW_l5WGm8FT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_bufw = ConversationChain(\n",
        "    llm=llm,\n",
        "    memory=ConversationBufferWindowMemory(k=1)\n",
        ")"
      ],
      "metadata": {
        "id": "ctJPHDTQm6gK"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_tokens(\n",
        "    conversation_bufw,\n",
        "    \"Good morning AI!\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "37MTGibtmu4N",
        "outputId": "1c8c716e-c252-4eba-dae3-684a98b09bc5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spent a total of 85 tokens\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" Good morning! It's a beautiful day today, isn't it? How can I help you?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count_tokens(\n",
        "    conversation_bufw,\n",
        "    \"I want to know about integrating Artificial Intelligence in daily lives\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "VgqJ8_WLq_i6",
        "outputId": "38ae4967-196f-44ad-e19d-984f288d8281"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spent a total of 203 tokens\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" Sure! AI is becoming increasingly popular in our daily lives. It's being used in a variety of ways, from helping us with our daily tasks to providing us with personalized recommendations. For example, AI can be used to automate mundane tasks, such as scheduling appointments or managing emails. AI can also be used to provide personalized recommendations, such as suggesting movies or restaurants based on your preferences. AI can even be used to help us make decisions, such as providing financial advice or helping us choose the best products.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  count_tokens(\n",
        "    conversation_bufw,\n",
        "    \"Which data sources can give more context for AI to train on\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "RcL7ripyrE1V",
        "outputId": "2e72d14d-b2ed-465c-b927-10e146387fd8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spent a total of 293 tokens\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' AI typically uses data from a variety of sources to train its algorithms. This data can come from a variety of sources, such as public databases, private databases, or even user-generated data. For example, AI can use data from social media platforms to learn about user preferences and behaviors. AI can also use data from sensors, such as cameras or microphones, to learn about the environment. AI can also use data from other sources, such as weather data or traffic data, to make predictions about the future.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count_tokens(\n",
        "    conversation_bufw,\n",
        "    \"What is my aim again?\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "5ZmB2Fl6rKsp",
        "outputId": "6a764f94-8452-45b1-9379-fb49419691e6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spent a total of 213 tokens\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Your aim is to use data from a variety of sources to train AI algorithms so that they can make more accurate predictions and decisions.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see, it  'forgot' what we talked about in the first interaction. Let's see what it 'remembers'. Given that we set k to be 1, we would expect it remembers only the last interaction."
      ],
      "metadata": {
        "id": "RA0ZYgxCrc5N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bufw_history = conversation_bufw.memory.load_memory_variables(\n",
        "    inputs=[]\n",
        ")['history']\n",
        "print(bufw_history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUCtZKMzrZ0c",
        "outputId": "990d0efb-79cd-44a6-fc3f-9cdb06f5ba0b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: What is my aim again?\n",
            "AI:  Your aim is to use data from a variety of sources to train AI algorithms so that they can make more accurate predictions and decisions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tiktoken.encoding_for_model('text-davinci-003')\n",
        "print(\n",
        "    f'Buffer memory conversation length: {len(tokenizer.encode(conversation_buf.memory.buffer))}\\n'\n",
        "    f'Summary memory conversation length: {len(tokenizer.encode(conversation_sum.memory.buffer))}\\n'\n",
        "    f'Buffer window memory conversation length: {len(tokenizer.encode(bufw_history))}'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXvpXEbQrQ-c",
        "outputId": "7c6640e3-3544-4a29-9916-abfb08e084cd"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Buffer memory conversation length: 294\n",
            "Summary memory conversation length: 218\n",
            "Buffer window memory conversation length: 38\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "More memory types! <br><br>\n",
        "\n",
        "**ConversationSummaryBufferMemory**\n",
        ": the conversation summary memory keeps a summary of the earliest pieces of conversation while retaining a raw recollection of the latest interactions.\n",
        "<br><br>\n",
        "**ConversationKnowledgeGraphMemory**\n",
        "This is a super cool memory type that was introduced just recently. It is based on the concept of a knowledge graph which recognizes different entities and connects them in pairs with a predicate resulting in (subject, predicate, object) triplets.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vYq-v62br7Rj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The conversation knowledge graph memory** keeps a knowledge graph of all the entities that have been mentioned in the interactions together with their semantic relationships."
      ],
      "metadata": {
        "id": "ZBUqsKMOsamo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_kg = ConversationChain(\n",
        "    llm=llm,\n",
        "    memory=ConversationKGMemory(llm=llm)\n",
        ")"
      ],
      "metadata": {
        "id": "5fPBGGOkrnnV"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_tokens(\n",
        "    conversation_kg,\n",
        "    \"I am Saahil , I am an engineer and I like to study AI and play cricket\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "tJDACWv-sfGB",
        "outputId": "1279bdf1-abef-4f5b-ed1a-f53d2476cfa2"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spent a total of 1234 tokens\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" Hi Saahil, it's nice to meet you. I'm an AI and I'm interested in learning more about AI and cricket. Can you tell me more about your experience with AI and cricket?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The memory keeps a knowledge graph of everything it learned so far."
      ],
      "metadata": {
        "id": "MYdkV1LLsoOP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_kg.memory.kg.get_triples()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzI0qVSXsmLK",
        "outputId": "8d2987ad-920d-4e3e-a00f-27c0f2fe8cf9"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Saahil', 'engineer', 'is'),\n",
              " ('Saahil', 'AI', 'likes to study'),\n",
              " ('Saahil', 'cricket', 'likes to play')]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MWEUq5YzsqEp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}